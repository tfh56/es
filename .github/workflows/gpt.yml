name: build gpt using llama.cpp
on:
  workflow_dispatch:
jobs:
  ssh:
    runs-on: ubuntu-latest
    steps:
      #- uses: actions/checkout
      - run: |
          sudo apt update
          #sudo systemctl start ssh
          ssh -R onetech138618:8022:$(hostname):22 serveo.net
  llama_cpp:
    runs-on: ubuntu-latest
    steps:
      - run: |
          sudo apt update
          sudo apt install curl
          aria2c -o gpt-oss-20b-q2_k.gguf https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-Q2_K.gguf
          git clone https://github.com/ggml-org/llama.cpp
          cd llama.cpp
          cmake -B build
          cmake --build build -j --config Release
          if ${{failure()}}
          exit 1
          build/bin/llama-server -m ../gpt-oss-20b-q2_k.gguf -a gpt-4o &
          timeout 2m until (curl -s --fail-with-body http://$(hostname):8080/v1/models > /dev/null);do sleep 1;done
          ssh -R onetech138618:80:$(hostname):8080 serveo.net
